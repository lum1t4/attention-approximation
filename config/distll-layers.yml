params:
  model_config_path: data/MobileLLM/config.json
  model_weights_path: data/MobileLLM/model.safetensors
  data_path: data/minipile
  checkpoint_dir: checkpoints
  device: cuda

  # Training settings
  max_steps: 1000
  batch_size: 12 # (Rank, Optimal BS) = (128, 8), (64, 16), (32, 32), (16, 64)
  seq_length: 512
  gradient_accumulation_steps: 4
  learning_rate: 0.001
  min_learning_rate: 0.00001
  weight_decay: 0.00001
  warmup_steps: 100
  grad_clip: 1.0

  # Logging & saving
  log_interval: 10
  save_interval: 100
  val_interval: 250
  val_batches: 10

  # Distillation-specific
  factorization_rank: 128
  layer_sharing: true
  use_dataparallel: false