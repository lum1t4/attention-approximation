params:
  # Model and Data Paths
  model_config_path: "data/MobileLLM/config.json"
  model_weights_path: "data/MobileLLM/model.safetensors"
  data_path: "data/minipile"
  checkpoint_dir: checkpoints
  device: cuda

  # Training settings
  # 100M tokens / (512 seq_length * 16 batch_size * 8 grad_accum_steps * 4 world size) ~= 381 steps
  max_steps: 400
  seed: 1337
  amp: true
  dtype: "bfloat16"  # float16 or bfloat16
  workers: 1
  batch_size: 16
  seq_length: 512
  grad_accum_steps: 8
  lr: 0.001
  min_lr: 0.00001
  weight_decay: 0.00001
  grad_clip: 1.0

  # Monitoring, Logging & saving
  val: "validation"
  save_interval: 10
  val_interval: 50

  # Student Model Configuration
  factorization_rank: 128
  layer_sharing: false

  # Tracker
  tracker: null
  project: "attention-approximation"

  # To review
  warmup_steps: 100